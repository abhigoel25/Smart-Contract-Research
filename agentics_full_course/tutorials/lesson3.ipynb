{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Agentics Mini Tutorial\n",
    "\n",
    "Agentics provides the implementation of **AG**, a powerful datatype that connects\n",
    "LLMs to Pydantic objects and enables **logical transduction**.\n",
    "\n",
    "---\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "!uv pip install agentics-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv pip install agentics-py\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "CURRENT_PATH = \"\"\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "print(\"In Colab:\", IN_COLAB)\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    CURRENT_PATH = \"/content/drive/MyDrive/\"\n",
    "    # Mount your google drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    from google.colab import userdata\n",
    "\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your GEMINI_API_KEY:\")\n",
    "else:\n",
    "\n",
    "    CURRENT_PATH = os.getcwd()\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your GEMINI_API_KEY:\")\n",
    "\n",
    "base = Path(CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Use Agentics as Lists\n",
    "\n",
    "Agentics objects (`AG`) can be used similarly to Python lists, allowing you to store and manage collections of states. You can append new elements using the `.append()` method, and access all states via the `.states` attribute.\n",
    "\n",
    "For example, after creating an empty `AG` object, you can add elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentics import AG\n",
    "\n",
    "my_first_agentics = AG()\n",
    "\n",
    "print(\"The agentics is empty :\", len(my_first_agentics))\n",
    "\n",
    "## Add elements to the list\n",
    "my_first_agentics.append(\"Alfio\")\n",
    "## internally, agentics stores the elements in the attribute states\n",
    "my_first_agentics.states += [\"Naweed\", \"Junkyuu\"]\n",
    "\n",
    "print(\"The agentics now has more instances :\", len(my_first_agentics))\n",
    "\n",
    "try:\n",
    "    print(\"this triggers an error\")\n",
    "    my_first_agentics = my_first_agentics + my_first_agentics\n",
    "except:\n",
    "    my_first_agentics.states = my_first_agentics.states + my_first_agentics.states\n",
    "    print(\n",
    "        \"This is the right way to concetenate two agentics. Be careful, the states should be instances of the same atype\"\n",
    "    )\n",
    "    my_first_agentics.pretty_print()\n",
    "\n",
    "print(\"Iterating over agentics:\")\n",
    "for state in my_first_agentics:\n",
    "    print(state)\n",
    "\n",
    "print(\"Be careful, the AG itself is not a list :\", my_first_agentics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Atypes\n",
    "\n",
    "Agentics supports **typed AGs** using Pydantic models, enabling you to enforce schema validation and structure on the states stored in an AG. This is useful when you want all elements in your AG to follow a specific format or contain certain fields.\n",
    "\n",
    "To define a typed AG:\n",
    "\n",
    "1. **Create a Pydantic model** that describes the schema for your states.\n",
    "2. **Instantiate an AG** with the `atype` parameter set to your Pydantic model.\n",
    "3. **Add instances** of your model to the AG. Only objects matching the schema will be accepted.\n",
    "\n",
    "This approach ensures data consistency and allows you to leverage Pydantic's validation features within Agentics workflows.\n",
    "\n",
    "For example, you can define a `Movie` type and create an AG that only accepts `Movie` instances as its states. See the next cell for a practical demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "from agentics import AG\n",
    "\n",
    "\n",
    "# Define the Movie Pydantic model for use with Agentics AG\n",
    "class Movie(BaseModel):\n",
    "    movie_name: Optional[str] = None\n",
    "    genre: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "\n",
    "\n",
    "movies = AG(atype=Movie)\n",
    "movies.append(Movie(movie_name=\"La dolce vita\"))\n",
    "movies.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Extending and Merging AGs\n",
    "AGs can evolve by adding new fields or combining with other AGs to form richer schemas.\n",
    "\n",
    "### Add attributes\n",
    "Use `.add_attribute()` to dynamically extend the schema of an AG.  \n",
    "This operation mutates the AG in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = AG(atype=Movie)\n",
    "movies.append(Movie(movie_name=\"La dolce vita\"))\n",
    "movies.pretty_print()\n",
    "\n",
    "print(\"adding a new attribute to the type and rebinding the object\")\n",
    "movies = movies.add_attribute(\n",
    "    \"email\",\n",
    "    description=\"Write an email to tell a fried about this movie\",\n",
    "    slot_type=Optional[str],\n",
    ")\n",
    "\n",
    "movies.pretty_print()\n",
    "print(\"Note that the AG changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Subtypes\n",
    "You can project an AG onto a subset of its fields, e.g. `movies(\"title\", \"genre\")`.  \n",
    "This creates a new AG without modifying the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_subtype = movies(\"movie_name\", \"genre\")\n",
    "print(\"This is a subtype\")\n",
    "movies_subtype.pretty_print()\n",
    "\n",
    "print(\"This is the original type.\\nNote that the AG didn't change after subtype\")\n",
    "movies.pretty_print()\n",
    "print(\"Note that the AG didn't change after subtyping it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Import Agentics for Json and CSV \n",
    "\n",
    "Agentics AG objects can be easily imported from and exported to CSV and JSONL formats. This enables seamless integration with tabular and structured data workflows.\n",
    "\n",
    "- **CSV Import/Export:**  \n",
    "    Use `AG.from_csv(\"path/to/file.csv\")` to create an AG from a CSV file. The schema (`atype`) can be inferred automatically or provided explicitly.\n",
    "- **JSONL Import/Export:**  \n",
    "    Use `AG.to_jsonl(\"path/to/file.jsonl\")` to export, and `AG.from_jsonl(\"path/to/file.jsonl\")` to import AG objects in JSON Lines format.\n",
    "\n",
    "This functionality allows you to move data between Agentics and other tools with minimal effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new AG object from the provided csv file\n",
    "movies = AG.from_csv(base / \"data/movies.csv\", max_rows=3)\n",
    "movies.pretty_print()\n",
    "\n",
    "# Note that the atype has been automatically inffered\n",
    "print(\"Imported Type\", movies.atype)\n",
    "\n",
    "# Reloading same file by providing atype\n",
    "movies = AG.from_csv(base / \"data/movies.csv\", atype=Movie)\n",
    "\n",
    "# Note that just a subset of the attributes have been imported\n",
    "print(\"Provided Type\", movies.atype)\n",
    "\n",
    "# agentics can be exported and imported from jsonl objects\n",
    "movies.to_jsonl(base / \"data/movies.jsonl\")\n",
    "movies = AG.from_jsonl(base / \"data/movies.jsonl\")\n",
    "\n",
    "# note this type is different from what imported from csv\n",
    "print(\"Imported atype from jsonl: \", movies.atype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Logical Transduction\n",
    "\n",
    "Once an AG is initialized with an atype, Agentics can **transduce** any string of text and/or pydantic object into that type.  If a list of strings is provided, they are processed asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Untyped transduction\n",
    "\n",
    "If no target atype is provided, transduction works as a regular llm call, where the input text or pydantic object is given to the LLM and the output is the LLM response. In this use case, agentics provides an off the shelp **async scale-out framework for LLM calls**. \n",
    "\n",
    "Note that no AType is specified, the output of transduction is alist of strings. So it is not recommended to use this notation for transduction algebra. In addition, Unconstrained trnasduction tends to me less efficient as it requires the LLM to guess the type of output required, often resulting in verbose and unecessary information . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "questions = [\n",
    "    \"What are the benefits of using Agentic AI for data workflows?\",\n",
    "    \"Will AI improve working conditions for the middle class?\",\n",
    "    \"How can Agentic AI enhance decision-making in finance?\",\n",
    "    # \"What risks should companies consider when adopting AI agents?\",\n",
    "    # \"Can AG objects integrate with existing data pipelines?\",\n",
    "    # \"Who won the latest FIFA worldcup\",\n",
    "]\n",
    "start = time.time()\n",
    "answers = await (AG() << questions)\n",
    "end = time.time()\n",
    "\n",
    "for question, answer in zip(questions, answers):\n",
    "    print(f\"Question: {question}\\nAnswer{answer}\\n\")\n",
    "print(f\"Uncostrained transduction done in {end-start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Transduction into Atype\n",
    "\n",
    "You can define a target schema with Pydantic (e.g., `Answer`) and transduce text into it.  \n",
    "The LLM output is parsed and validated into the fields `answer`, `justification`, and `confidence`.  \n",
    "Note that the output is more clean and organized, and the time required to execute the transduction is one order of magnitude lower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic model for a structured answer\n",
    "class Answer(BaseModel):\n",
    "    # The main response text\n",
    "    answer: Optional[str] = None\n",
    "    # An explanation or reasoning behind the answer\n",
    "    justification: Optional[str] = None\n",
    "    # A numeric confidence score (e.g. from 0.0 to 1.0)\n",
    "    confidence: Optional[float] = None\n",
    "\n",
    "\n",
    "# Transduce a natural language question into the structured Answer schema\n",
    "start = time.time()\n",
    "answers = await (AG(atype=Answer) << questions)\n",
    "end = time.time()\n",
    "print(f\"Typed transduction done in {end-start} seconds\")\n",
    "answers.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Transduction Between AGs\n",
    "\n",
    "You can control transduction more precisely by converting **from one AG to another**:\n",
    "- The **source AG** provides the input states (rendered via the prompt).\n",
    "- The **target AG** defines the output schema and validation.\n",
    "- Agentics renders each source state → sends it to the LLM → parses into the target type.\n",
    "\n",
    "This pattern is ideal when you want consistent, structured outputs from heterogeneous inputs while keeping prompts and schema separate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Transduction Between AGs  \n",
    "Here we convert product reviews (`ProductReview`) into sentiment summaries (`SentimentSummary`).  \n",
    "The source AG provides the reviews, and the target AG enforces structured outputs (positive/neutral/negative with a reason).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Literal\n",
    "from pydantic import BaseModel\n",
    "from agentics import AG\n",
    "\n",
    "\n",
    "# Source schema: product reviews\n",
    "class ProductReview(BaseModel):\n",
    "    reviewer: Optional[str] = None\n",
    "    text: Optional[str] = None\n",
    "    stars: Optional[int] = None\n",
    "\n",
    "\n",
    "# Target schema: summarized sentiment\n",
    "class SentimentSummary(BaseModel):\n",
    "    customer_sentiment: Optional[Literal[\"positive\", \"neutral\", \"negative\"]] = None\n",
    "    reason: Optional[str] = None\n",
    "\n",
    "\n",
    "# Example reviews\n",
    "reviews = [\n",
    "    ProductReview(\n",
    "        reviewer=\"Alice\", text=\"Excellent quality and fast delivery!\", stars=5\n",
    "    ),\n",
    "    ProductReview(reviewer=\"Bob\", text=\"Okay, but packaging was damaged\", stars=3),\n",
    "    ProductReview(reviewer=\"Carol\", text=\"Terrible, broke after one use\", stars=1),\n",
    "]\n",
    "\n",
    "# Create source and target AGs\n",
    "source = AG(atype=ProductReview, states=reviews)\n",
    "target = AG(atype=SentimentSummary, provide_explanations=True)\n",
    "\n",
    "# Transduce reviews into sentiment summaries\n",
    "sentiments = await (target << source)\n",
    "\n",
    "sentiments.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Self-Transduction  \n",
    "\n",
    "You can transduce within the same AG type by selecting different subsets of fields.  \n",
    "This is useful for projecting, comparing, or enriching dataframes and state graphs without changing the original AG.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = AG.from_csv(base / \"data/movies.csv\", atype=Movie)\n",
    "movies.filter_states(start=10, end=20)\n",
    "\n",
    "self_transductions = await movies.self_transduction(\n",
    "    [\"movie_name\", \"description\"], [\"genre\"]\n",
    ")\n",
    "print(self_transductions.pretty_print())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Customizing Transduction  \n",
    "\n",
    "You can fine-tune how logical transduction works by configuring:  \n",
    "\n",
    "- **LLMs** – choose the underlying language model to run the transduction.  \n",
    "- **Instructions** – add task-specific guidance for the LLM.  \n",
    "- **Prompt Templates** – control how inputs are rendered into prompts.  \n",
    "- **Few-Shot Examples** – provide examples to steer the model’s behavior.  \n",
    "- **Verbose Options** – enable detailed logging and debug outputs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### Task instructions\n",
    "The example below illustrate how to provide a llm and task specific instructions to transduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_answering_ag = AG(\n",
    "    atype=Answer, llm=AG.get_llm_provider(\"watsonx\"), instructions=\"Answer in italian\"\n",
    ")\n",
    "\n",
    "print((await (questions_answering_ag << questions)).pretty_print())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### Prompt templates\n",
    "\n",
    "Prompt templates enable greater customization of your transductions by providing a langchain style abstraction to render pydantic objects into input prompts for the agent. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_answering_ag = AG(atype=Answer)\n",
    "\n",
    "dow_jones_data = AG.from_csv(\"data/dow_jones.csv\")\n",
    "dow_jones_data = dow_jones_data.get_random_sample(0.002)\n",
    "dow_jones_data.prompt_template = \"what happened to the financial markets in {date}?\"\n",
    "answers = await (questions_answering_ag << dow_jones_data)\n",
    "print(answers.pretty_print())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Few-Shot Learning\n",
    "\n",
    "Agentics natively supports **few-shot examples**: you can preload the **target AG** with\n",
    "gold states (examples of the desired output). During transduction, these examples steer\n",
    "the LLM toward consistent labels/structures.\n",
    "\n",
    "Below, we load movies from CSV, manually seed the first 10 labels as few-shots, and then\n",
    "transduce the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Shots= all output states are blank\n",
    "movies = AG.from_csv(base / \"data/movies.csv\", atype=Movie)\n",
    "movies.filter_states(start=10, end=20)\n",
    "self_transductions = await movies.self_transduction(\n",
    "    [\"movie_name\", \"description\"], [\"genre\"]\n",
    ")\n",
    "print(\"this is zero shot\")\n",
    "self_transductions.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few shots = the first 10 states are used as examples\n",
    "movies = AG.from_csv(base / \"data/movies.csv\", atype=Movie)\n",
    "movies.filter_states(start=0, end=20)\n",
    "self_transductions = await movies.self_transduction(\n",
    "    [\"movie_name\", \"description\"], [\"genre\"]\n",
    ")\n",
    "\n",
    "# printing only transduced states\n",
    "movies.filter_states(start=10, end=20)\n",
    "print(\"this is the output with 10 shots\")\n",
    "self_transductions.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Tool Usage  \n",
    "\n",
    "Agentics integrates seamlessly with the **MCP ecosystem**, allowing AGs to call external tools during transduction.  In addition to that, they also allows the use of CrewAI tools, as the underlying transduction framework is currently based on crewAI agents. \n",
    "\n",
    "This makes it easy to fetch, process, or enrich data dynamically while keeping results structured. \n",
    "\n",
    "In the following example we illustrate the use of Duck Duck Go search to improve the information gathering of historical market data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.tools import tool\n",
    "from ddgs import DDGS\n",
    "\n",
    "\n",
    "## Define a Crew AI tool to get news for a given date using the DDGS search engine\n",
    "@tool(\"web_search\")\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Fetch web search results for the given query using DDGS.\"\"\"\n",
    "    return str(DDGS().text(query, max_results=10))\n",
    "\n",
    "\n",
    "questions_answering_ag.verbose_agent = True\n",
    "questions_answering_ag.tools = [web_search]\n",
    "dow_jones_data.filter_states(end=1)\n",
    "answers = await (questions_answering_ag << dow_jones_data)\n",
    "print(answers.pretty_print())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
